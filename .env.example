# StreamStack Configuration
# Copy this file to .env and customize for your environment

# =============================================================================
# Application Settings
# =============================================================================
STREAMSTACK_APP_NAME=StreamStack
STREAMSTACK_VERSION=0.1.0
STREAMSTACK_DEBUG=false
STREAMSTACK_LOG_LEVEL=INFO

# Server Configuration
STREAMSTACK_HOST=0.0.0.0
STREAMSTACK_PORT=8000
STREAMSTACK_WORKERS=1

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Provider Type: openai, vllm, or custom
STREAMSTACK_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
STREAMSTACK_OPENAI_BASE_URL=https://api.openai.com/v1
STREAMSTACK_OPENAI_MODEL=gpt-3.5-turbo

# vLLM Configuration
STREAMSTACK_VLLM_BASE_URL=http://localhost:8001
STREAMSTACK_VLLM_MODEL=meta-llama/Llama-2-7b-chat-hf

# =============================================================================
# Redis Configuration
# =============================================================================
STREAMSTACK_REDIS_URL=redis://localhost:6379/0
STREAMSTACK_REDIS_MAX_CONNECTIONS=100

# =============================================================================
# Queue Management
# =============================================================================
STREAMSTACK_MAX_QUEUE_SIZE=1000
STREAMSTACK_REQUEST_TIMEOUT=300
STREAMSTACK_QUEUE_CHECK_INTERVAL=0.1

# =============================================================================
# Rate Limiting
# =============================================================================
STREAMSTACK_RATE_LIMIT_REQUESTS_PER_MINUTE=100
STREAMSTACK_RATE_LIMIT_TOKENS_PER_MINUTE=10000
STREAMSTACK_RATE_LIMIT_BURST_SIZE=10

# =============================================================================
# Observability
# =============================================================================

# Metrics
STREAMSTACK_ENABLE_METRICS=true
STREAMSTACK_METRICS_PATH=/metrics

# Tracing
STREAMSTACK_ENABLE_TRACING=true
STREAMSTACK_JAEGER_ENDPOINT=http://localhost:14268/api/traces

# Health Checks
STREAMSTACK_HEALTH_CHECK_TIMEOUT=30

# =============================================================================
# Security
# =============================================================================
STREAMSTACK_ENABLE_CORS=true
STREAMSTACK_CORS_ORIGINS=["*"]
STREAMSTACK_API_KEY_HEADER=X-API-Key

# =============================================================================
# Development Settings
# =============================================================================

# Set to true for development
# STREAMSTACK_DEBUG=true
# STREAMSTACK_LOG_LEVEL=DEBUG

# Use local vLLM for development
# STREAMSTACK_PROVIDER=vllm
# STREAMSTACK_VLLM_BASE_URL=http://localhost:8001

# =============================================================================
# Production Settings
# =============================================================================

# For production, ensure:
# - STREAMSTACK_DEBUG=false
# - Use strong API keys
# - Configure proper CORS origins
# - Set appropriate rate limits
# - Use production Redis instance
# - Configure proper logging level

# Example production values:
# STREAMSTACK_DEBUG=false
# STREAMSTACK_LOG_LEVEL=INFO
# STREAMSTACK_WORKERS=4
# STREAMSTACK_CORS_ORIGINS=["https://yourdomain.com"]
# STREAMSTACK_RATE_LIMIT_REQUESTS_PER_MINUTE=1000
# STREAMSTACK_REDIS_URL=redis://prod-redis:6379/0